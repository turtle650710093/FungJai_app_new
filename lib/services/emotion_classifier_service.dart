import 'dart:typed_data';
import 'package:flutter/services.dart';
import 'package:tflite_flutter/tflite_flutter.dart';


class EmotionClassifierService {
  late Interpreter _interpreter;
  late List<String> _labels;

  EmotionClassifierService() {
    _loadModel();
  }

  Future<void> _loadModel() async {
    // ‡πÇ‡∏´‡∏•‡∏î labels ‡∏à‡∏≤‡∏Å assets
    final labelsData = await rootBundle.loadString('assets/models/labels.txt');
    _labels = labelsData.split('\n').where((label) => label.isNotEmpty).toList();

    // ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• TFLite
    _interpreter = await Interpreter.fromAsset('assets/models/emotion_model.tflite'); 
    print('‚úÖ Model and labels loaded successfully');
  }

  Future<List<List<List<double>>>> _preprocessAudio(String audioPath) async {
    // 1. ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡πÄ‡∏ä‡πà‡∏ô .wav)
    // ‡πÉ‡∏ä‡πâ package ‡∏≠‡∏¢‡πà‡∏≤‡∏á 'wav' ‡∏´‡∏£‡∏∑‡∏≠ 'sound' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô Float32List
    // final audioBytes = await File(audioPath).readAsBytes();
    // final wav = Wav.read(audioBytes);
    // final audioSamples = wav.toMono(); // ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Mono

    // 2. ‡∏™‡∏Å‡∏±‡∏î MFCCs
    // ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ library ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô `fftea` ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡πà‡∏≤
    // ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ n_mfcc, n_fft, hop_length ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏õ‡πä‡∏∞‡πÜ
    // final mfccs = calculateMfccs(audioSamples, n_mfcc: 40, ...);

    // 3. Reshape ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Input ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
    // ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏£‡∏±‡∏ö input shape [1, n_mfcc, time_steps, 1]
    // final reshapedMfccs = reshape(mfccs, [1, 40, 173, 1]); // << ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
    
    // *** ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏°‡∏≤‡∏Å ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° ***
    // ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏à‡∏£‡∏¥‡∏á ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á implement ‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå
    // ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á
    // ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ input shape ‡∏Ñ‡∏∑‡∏≠ [1, 40, 173, 1]
    final inputShape = _interpreter.getInputTensor(0).shape; // [1, 40, 173, 1]
    final dummyInput = List.generate(
      inputShape[0],
      (_) => List.generate(
        inputShape[1],
        (_) => List.generate(inputShape[2], (_) => [0.5]), // [0.5] for the channel
      ),
    );
    // ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (‡∏°‡∏±‡∏Å‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô Float32)
    var processedInput = dummyInput.map((plane) => plane.map((row) => List<double>.from(row)).toList()).toList();
    // ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏≥‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏Å‡∏±‡∏î MFCCs ‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà dummy data ‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
    // return reshapedMfccs;
    
    // ‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á ‡πÅ‡∏ï‡πà‡∏Å‡∏≤‡∏£‡∏™‡∏Å‡∏±‡∏î MFCC ‡πÉ‡∏ô Dart ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á
    // ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏£‡∏±‡∏ö
    print("‚ö†Ô∏è  Warning: Using dummy data for preprocessing.");
    // ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô dynamic list ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ TFLite ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ
    return dummyInput.cast<List<List<double>>>();
  }

  Future<Map<String, double>> predict(String audioPath) async {
    // 1. Preprocess the audio file to get MFCCs
    // var input = await _preprocessAudio(audioPath); 
    // ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å _preprocessAudio ‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô dummy ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á input ‡∏ï‡∏≤‡∏° shape ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    final inputShape = _interpreter.getInputTensor(0).shape; // [1, 40, 173, 1]
    var input = List.filled(inputShape[0] * inputShape[1] * inputShape[2] * inputShape[3], 0.0)
        .reshape(inputShape);


    // 2. Prepare the output buffer
    final outputShape = _interpreter.getOutputTensor(0).shape; // e.g., [1, 5] for 5 emotions
    var output = List.filled(outputShape[0] * outputShape[1], 0.0).reshape(outputShape);

    // 3. Run inference
    _interpreter.run(input, output);

    // 4. Post-process the output
    final result = <String, double>{};
    final probabilities = output[0] as List<double>; // Get the list of probabilities

    for (int i = 0; i < _labels.length; i++) {
      result[_labels[i]] = probabilities[i];
    }
    
    print('üìä Prediction Results: $result');
    return result;
  }
}